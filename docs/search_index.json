[["index.html", "Rでやるランダムフォレスト はじめに", " Rでやるランダムフォレスト Akiru Kato 2023-03-11 はじめに R（tidymodels）でrangerのランダムフォレストを使ってみます require(tidymodels) require(textrecipes) tidymodels::tidymodels_prefer() "],["intro.html", "Chapter 1 Introduction 1.1 rangerのランダムフォレストについて 1.2 ハイパーパラメータ 1.3 その他の引数", " Chapter 1 Introduction ランダムフォレストは Breiman (2001) で提案された教師あり学習の手法です。 集団学習（ensemble learning, アンサンブル学習）のなかでもバギングと呼ばれるやつで、複数の弱学習器（決定木）を組み合わせています。 ランダムフォレストは次のような特徴があるとされていて、とくに2010年代前半ごろまでよく使われていました。 過学習が起こりにくいとされ、扱いやすい 高次元だったり、相関があったりするデータでもわりと大丈夫 欠損値がある・不均衡なデータでもわりと大丈夫 木をつくるのは並列実行できるので、速い 変数重要度を確認できる 現在では勾配ブースティング系のアルゴリズムのほうが強力なので、以前のようには使われませんが、高次元のデータでも使えてそれなりに速く、変数重要度を確認できるため、とりあえずランダムフォレストに突っ込んで特徴量選択するみたいな使い方ができるようです。 1.1 rangerのランダムフォレストについて この資料では、tidymodelsからrangerのランダムフォレストを使います。 parsnip::rand_forestでは、以下のエンジンを使用することができます。デフォルトでは、rangerのランダムフォレストが使用されます。 ranger aorsf h2o randomForest spark Wright and Ziegler (2017) は、randomForestよりも後発の実装です。 1.2 ハイパーパラメータ parsnip::rand_forestの各エンジンに共通するハイパーパラメータは次の３つです。 mtry（木を作成するときに使う特徴量の数） trees（作成する木の数） min_n（ノードサイズの下限値） tidymodelsの枠組みのなかでは、mtryとtreesを調整します。 1.2.1 mtry（木を作成するときに使う特徴量の数） mtryです。scikit-learnにおけるmax_featuresのようなものですが、max_featuresとは異なり、それぞれの木をつくるときに使用する特徴量の数をintegerで直接指定します。 mtryのデフォルト値はfloor(sqrt(ncol(x)))となっています。ranger::rangerでは引数を受け取ってinteger scalarを返す関数を指定してもよいことになっていますが、tidymodelsのなかではintegerしか指定できません。 1.2.2 trees（作成する木の数） num.treesです。scikit-learnにおけるn_estimatorsにあたります。 デフォルト値は500Lになっています。 treesは大きいほうが精度が上がりますが、そのぶん学習にかかる時間も増えます。また、十分に大きくすると、それ以上大きくしてもあまり性能が改善しなくなるため、ふつうは適度な大きさで決め打ちします。 1.2.3 min_n（ノードサイズの下限値） min.node.sizeです。scikit-learnにおけるmin_samples_splitのようなものです。 デフォルト値は分類の場合は1L、回帰の場合は5Lです。 min_nについては、max.depth=NULLの場合、最小ノードサイズを1にしたときによい結果が得られやすいとされています（1.11. Ensemble methods — scikit-learn 1.2.2 documentation）。ただし、そのぶん過学習は起こりやすくなります。また、一つ一つの木が深くなると学習に時間がかかるようになるため、速く学習を終わらせたいときには、この値を大きくして調整します。 1.3 その他の引数 ranger::rangerの引数はたくさんありますが、ハイパーパラメータは上の3つなので、他の引数についてはあまり触る機会はないです。 1.3.1 imporatnce 変数重要度を出したい場合、分類ではimpurity、回帰ではpermutationを指定します。 なお、impurityベースの変数重要度については注意して使いましょうという議論もあります。 1.3.2 num.threads ranger::rangerはデフォルトでは利用可能なCPUコア数と同じ数のスレッドを使用しますが、parsnipのヘルプによると、parsnip::rand_forestではマルチスレッドでの実行は無効になっています。このため、マルチスレッドでの学習を有効にしたい場合は、parsnip::set_engineにranger::rangerに渡されるnum.threads引数を明示的に指定します。 References "],["summary.html", "Chapter 2 Summary 2.1 データセット 2.2 分析", " Chapter 2 Summary 2.1 データセット ここではAmazonの商品レビューのデータセットを使用し、レビューの内容などをもとに、商品カテゴリを目的変数として分類することを試みます。 dt &lt;- data.table::fread(&quot;https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz&quot;, quote = &quot;&quot;) このデータは、Amazon Customer Reviews Datasetのうち、日本語のレビューだけを抽出したものです。次の15列からなるデータで、欠損値のある行はありません。 marketplace - 2 letter country code of the marketplace where the review was written. customer_id - Random identifier that can be used to aggregate reviews written by a single author. review_id - The unique ID of the review. product_id - The unique Product ID the review pertains to. In the multilingual dataset the reviews for the same product in different countries can be grouped by the same product_id. product_parent - Random identifier that can be used to aggregate reviews for the same product. product_title - Title of the product. product_category - Broad product category that can be used to group reviews (also used to group the dataset into coherent parts). star_rating - The 1-5 star rating of the review. helpful_votes - Number of helpful votes. total_votes - Number of total votes the review received. vine - Review was written as part of the Vine program. verified_purchase - The review is on a verified purchase. review_headline - The title of the review. review_body - The review text. review_date - The date the review was written. dt |&gt; dplyr::glimpse() ## Rows: 262,431 ## Columns: 15 ## $ marketplace &lt;chr&gt; &quot;JP&quot;, &quot;JP&quot;, &quot;JP&quot;, &quot;JP&quot;, &quot;JP&quot;, &quot;JP&quot;, &quot;JP&quot;, &quot;JP&quot;, &quot;JP&quot;, &quot;JP&quot;, &quot;JP&quot;, &quot;JP… ## $ customer_id &lt;int&gt; 65317, 65317, 65696, 67162, 67701, 68380, 68655, 68973, 69080, 69552,… ## $ review_id &lt;chr&gt; &quot;R33RSUD4ZTRKT7&quot;, &quot;R2U1VB8GPZBBEH&quot;, &quot;R1IBRCJPPGWVJW&quot;, &quot;RL02CW5XLYONU&quot;… ## $ product_id &lt;chr&gt; &quot;B000001GBJ&quot;, &quot;B000YPWBQ2&quot;, &quot;B0002E5O9G&quot;, &quot;B00004SRJ5&quot;, &quot;B0093H8H8I&quot;,… ## $ product_parent &lt;int&gt; 957145596, 904244932, 108978277, 606528497, 509738390, 37188049, 9165… ## $ product_title &lt;chr&gt; &quot;SONGS FROM A SECRET GARDE&quot;, &quot;鏡の中の鏡‾ペルト作品集(SACD)(Arvo Part… ## $ product_category &lt;chr&gt; &quot;Music&quot;, &quot;Music&quot;, &quot;Music&quot;, &quot;Music&quot;, &quot;PC&quot;, &quot;Toys&quot;, &quot;Music&quot;, &quot;Electroni… ## $ star_rating &lt;int&gt; 1, 1, 5, 5, 4, 4, 5, 1, 5, 4, 3, 4, 5, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, … ## $ helpful_votes &lt;int&gt; 1, 4, 2, 6, 2, 2, 8, 3, 1, 1, 3, 0, 6, 1, 4, 1, 1, 3, 7, 8, 2, 1, 0, … ## $ total_votes &lt;int&gt; 15, 20, 3, 9, 4, 3, 13, 15, 2, 4, 6, 0, 9, 2, 6, 1, 1, 8, 14, 23, 4, … ## $ vine &lt;chr&gt; &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;N&quot;,… ## $ verified_purchase &lt;chr&gt; &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;,… ## $ review_headline &lt;chr&gt; &quot;残念ながら…&quot;, &quot;残念ながら…&quot;, &quot;ドリームキャスト&quot;, &quot;やっぱりマスト&quot;,… ## $ review_body &lt;chr&gt; &quot;残念ながら…趣味ではありませんでした。ケルト音楽の範疇にも幅があるの… ## $ review_date &lt;IDate&gt; 2012-12-05, 2012-12-05, 2013-03-02, 2013-08-11, 2013-02-10, 2014-02… 2.2 分析 このデータセットには26万2000件ほどのレビューが収録されていますが、レビューのほとんどはVideo DVDカテゴリとMusicカテゴリのものです。その他のカテゴリのレビューをすべて足し合わせても、Musicカテゴリのレビューの数よりも少なく、そもそもレビューが数件しかないようなカテゴリもあります。 また、商品の評価を表す星の数は5を付けているものが過半数であるほか、「このレビューが役に立った」の投票がないものがほとんどになっています。 dt |&gt; dtplyr::lazy_dt(immutable = TRUE) |&gt; dplyr::select(review_id, product_category, star_rating, helpful_votes, total_votes, vine, verified_purchase, review_headline, review_body, review_date) |&gt; dplyr::mutate( product_category = forcats::fct_lump(factor(product_category), n = 2), star_rating = forcats::fct_lump(factor(star_rating), n = 2), vine = factor(vine), verified_purchase = factor(verified_purchase), review_len = nchar(review_body), review_month = factor(lubridate::month(review_date)), review_wday = factor(lubridate::wday(review_date, label = TRUE)) ) |&gt; dplyr::select(!c(review_id, review_headline, review_body, review_date)) |&gt; dplyr::as_tibble() |&gt; DataExplorer::create_report(output_dir = &quot;docs&quot;) report レビュー本文は短いものが多く、比較的よくレビューが書かれている商品カテゴリ以外では、とくに短くなりがちです。 dt |&gt; dtplyr::lazy_dt(immutable = TRUE) |&gt; dplyr::select(review_id, product_category, review_headline, review_body) |&gt; dplyr::mutate( product_category = factor(product_category), review_len = nchar(review_body) ) |&gt; dplyr::filter(review_len &gt; 50, review_len &lt; 2000) |&gt; dplyr::summarise( counts = dplyr::n(), review_len = median(review_len), .by = product_category ) |&gt; dplyr::as_tibble() |&gt; ggplot2::ggplot(ggplot2::aes(x = counts, y = review_len, color = product_category)) + ggplot2::geom_point() + ggrepel::geom_text_repel(ggplot2::aes(label = product_category), max.overlaps = 15) + ggplot2::scale_x_log10() + ggplot2::theme(legend.position = &quot;none&quot;) + ggplot2::scale_colour_viridis_d(option = &quot;turbo&quot;) Figure 2.1: Product reviews and their length 分類を簡単にするために、ここでは使用するデータをある程度の文字数のあるレビューに絞りつつ、Video DVDとMusic以外のカテゴリを一つにまとめることにします。 dt |&gt; dtplyr::lazy_dt(immutable = TRUE) |&gt; dplyr::select(review_id, product_category, review_headline, review_body) |&gt; dplyr::mutate( product_category = forcats::fct_lump(factor(product_category), n = 2), review_len = nchar(review_body) ) |&gt; dplyr::select(product_category, review_len) |&gt; dplyr::as_tibble() |&gt; ggpubr::ggdensity( &quot;review_len&quot;, y = &quot;density&quot;, color = &quot;product_category&quot;, palette = viridisLite::turbo(3) ) |&gt; ggpubr::ggpar(xscale = &quot;log10&quot;) Figure 2.2: Density of review length "],["preprocess.html", "Chapter 3 Preprocessing 3.1 前処理 3.2 形態素解析の結果の確認", " Chapter 3 Preprocessing 3.1 前処理 データセットから10%だけ抽出して使用することにします。ここで一部の前処理もやってしまいます。 レビューのテキストについては、あらかじめ形態素解析をすませてから、スペース区切りのテキストとしてデータセットのなかに差し戻しておきます。tidymodelsの枠組みのなかでやってもよいのですが、形態素解析は文字列を分割する処理としてはわりと重いので、個人的には、学習とセットではやらないほうがよいかなと思います。 corp &lt;- dt |&gt; dtplyr::lazy_dt(immutable = TRUE) |&gt; dplyr::slice_sample(prop = .1) |&gt; dplyr::select( review_id, product_category, verified_purchase, star_rating, helpful_votes, total_votes, review_headline, review_body, review_date ) |&gt; dplyr::mutate( product_category = forcats::fct_lump(factor(product_category), n = 2), verified_purchase = factor(verified_purchase), star_rating = forcats::fct_lump(factor(star_rating), n = 2), review_len = nchar(review_body), review_month = factor(lubridate::month(review_date)), review_wday = factor(lubridate::wday(review_date, label = TRUE)) ) |&gt; dplyr::select(!review_date) |&gt; dplyr::filter(review_len &gt; 50, review_len &lt; 2000) |&gt; dplyr::as_tibble() ここではMeCab+IPA辞書で解析し、品詞が「助詞・助動詞・記号」である語と、品詞細分類1が「非自立」である語を取り除きます。 corp &lt;- corp |&gt; dplyr::select(review_id, review_headline, review_body) |&gt; dplyr::mutate(chunk_id = dplyr::ntile(dplyr::row_number(), 10)) |&gt; dplyr::group_by(chunk_id) |&gt; dplyr::group_map(\\(df, grp) { df |&gt; dplyr::mutate( review_body = stringi::stri_c(review_headline, review_body, sep = &quot;\\n\\n&quot;) |&gt; stringi::stri_replace_all_regex(&quot;(&lt;br /&gt;)&quot;, &quot;\\n\\n&quot;) |&gt; audubon::strj_normalize() |&gt; stringi::stri_trim_both() |&gt; stringi::stri_replace_all_regex(&quot;[\\\\d]+&quot;, &quot;0&quot;) ) |&gt; dplyr::select(review_id, review_body) |&gt; gibasa::tokenize(review_body, review_id) |&gt; dplyr::filter(!gibasa::is_blank(token)) |&gt; gibasa::prettify(col_select = c(&quot;POS1&quot;, &quot;POS2&quot;, &quot;Original&quot;)) |&gt; dplyr::mutate(token = dplyr::if_else(is.na(Original), token, Original)) |&gt; dplyr::add_count(doc_id, token) |&gt; gibasa::mute_tokens(POS1 %in% c(&quot;助詞&quot;, &quot;助動詞&quot;, &quot;記号&quot;)) |&gt; gibasa::mute_tokens(POS2 == &quot;非自立&quot;) |&gt; gibasa::pack() }) |&gt; purrr::list_rbind() |&gt; dplyr::left_join( corp |&gt; dplyr::select( review_id, product_category, verified_purchase, star_rating, helpful_votes, total_votes, review_len, review_month, review_wday ), by = c(&quot;doc_id&quot; = &quot;review_id&quot;) ) |&gt; dplyr::as_tibble() 3.2 形態素解析の結果の確認 後でtextrecipes::step_tokenfilterを使って語彙を減らすので、この段階で大体の語彙数を確認します。rsample::initial_splitはとくに何も指定しないと75%を訓練データにするので、コーパス全体の75%くらいについて、語彙数を確認しておきます。 corp |&gt; quanteda::corpus() %&gt;% quanteda::corpus_sample(x = ., size = floor(quanteda::ndoc(.) * .75)) |&gt; quanteda::tokens(what = &quot;fastestword&quot;) |&gt; quanteda::dfm() |&gt; quanteda::dfm_trim(min_termfreq = 100) |&gt; quanteda::nfeat() ## [1] 1904 corp |&gt; quanteda::corpus() %&gt;% quanteda::corpus_sample(x = ., size = floor(quanteda::ndoc(.) * .75)) |&gt; quanteda::tokens(what = &quot;fastestword&quot;) |&gt; quanteda::dfm() |&gt; quanteda::dfm_trim(min_termfreq = 100) |&gt; quanteda.textstats::textstat_frequency( n = 20L, groups = product_category, force = TRUE ) |&gt; ggpubr::ggdotchart( x = &quot;feature&quot;, y = &quot;frequency&quot;, group = &quot;group&quot;, color = &quot;group&quot;, palette = viridisLite::turbo(3), add = &quot;segment&quot;, rotate = TRUE ) + ggplot2::theme_bw() Figure 3.1: Frequent words in each category "],["modeling.html", "Chapter 4 Modeling 4.1 ワークフローの作成 4.2 ハイパーパラメータの探索 4.3 モデルの評価", " Chapter 4 Modeling 4.1 ワークフローの作成 ランダムフォレストのモデルを作成します。はじめに、モデルの学習に使うデータセットを分割します。 corp_split &lt;- initial_split(dplyr::select(corp, !doc_id), strata = product_category) corp_train &lt;- training(corp_split) corp_test &lt;- testing(corp_split) ワークフローを作成します。 先ほど形態素解析の結果について確認したとき、「映画」という語がコーパス全体の75%で1万回出ないくらいでしたが、これは特徴量として拾ってほしいので、textrecipes::step_tokenfilterのmax_timesは1e4とします。 また、コーパス全体の75%で語彙数が2000まではいかないくらいだったので、max_tokensはとりあえず300にしておきます。 ranger_spec &lt;- parsnip::rand_forest( mtry = tune::tune(), trees = tune::tune() ) |&gt; parsnip::set_engine( &quot;ranger&quot;, importance = &quot;impurity&quot;, num.threads = max(1, parallel::detectCores() - 1, na.rm = TRUE) ) |&gt; parsnip::set_mode(&quot;classification&quot;) tfidf_rec &lt;- recipes::recipe(product_category ~ ., data = corp_train) |&gt; recipes::step_YeoJohnson(all_numeric_predictors()) |&gt; themis::step_downsample(product_category, under_ratio = 2) |&gt; textrecipes::step_tokenize(text, custom_token = \\(x) { strsplit(x, &quot; &quot;, fixed = TRUE) }) |&gt; textrecipes::step_tokenfilter(text, min_times = 100, max_times = 1e4, max_tokens = 300) |&gt; textrecipes::step_tfidf(text, sublinear_tf = TRUE) corp_wflow &lt;- workflows::workflow() |&gt; workflows::add_model(ranger_spec) |&gt; workflows::add_recipe(tfidf_rec) 4.2 ハイパーパラメータの探索 treesとmtryについて、3分割CVで探索します。 ranger_tfidf_grid &lt;- corp_wflow |&gt; tune::tune_grid( resamples = rsample::vfold_cv(corp_train, strata = product_category, v = 3L), grid = dials::grid_latin_hypercube( list( dials::trees(range = c(100, 400)), dials::finalize( dials::mtry(), tfidf_rec |&gt; prep() |&gt; bake(new_data = NULL) |&gt; dplyr::select(!product_category) )) |&gt; dials::parameters(), size = 5L ), metrics = yardstick::metric_set(yardstick::f_meas), control = tune::control_grid(save_pred = TRUE) ) autoplot(ranger_tfidf_grid) 4.3 モデルの評価 last_fitして、F値を確認します。 corp_wflow_best &lt;- finalize_workflow(corp_wflow, select_best(ranger_tfidf_grid)) corp_last_fit &lt;- last_fit(corp_wflow_best, corp_split, metrics = metric_set(f_meas)) collect_metrics(corp_last_fit) ## # A tibble: 1 × 4 ## .metric .estimator .estimate .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 f_meas macro 0.884 Preprocessor1_Model1 混同行列を見ると、OtherをVideo DVDと誤分類している例がやや多いように見えます。 collect_predictions(corp_last_fit) |&gt; conf_mat(product_category, .pred_class) |&gt; autoplot(type = &quot;heatmap&quot;) Figure 4.1: Confusion matrix 変数重要度がとくに大きい特徴量を見てみると、Video DVDやMusicと同定するのに効いていそうな語彙が並んでいることがわかります。 corp_last_fit |&gt; extract_fit_parsnip() |&gt; (\\(x){ x$fit$variable.importance })() |&gt; tibble::enframe() |&gt; dplyr::slice_max(value, n = 25) |&gt; ggpubr::ggdotchart(x = &quot;name&quot;, y = &quot;value&quot;, rotate = TRUE, sorting = &quot;descending&quot;, add = &quot;segment&quot;, xlab = &quot;feature&quot;, ylab = &quot;importance&quot;) Figure 4.2: Variable importance OtherでVideo DVDと誤分類されている商品レビューは、どのようなレビューなのでしょうか。 サンプリングする前の元のデータセットから先頭2000行を取ってきて、学習したモデルでカテゴリを予測させてみて、同様に誤分類されたケースを確認してみます。 predict(extract_fit_parsnip(corp_last_fit), extract_preprocessor(corp_last_fit) |&gt; prep() |&gt; bake(new_data = dplyr::slice_head(corp, n = 2000) |&gt; dplyr::select(!doc_id))) |&gt; dplyr::bind_cols( dplyr::slice_head(corp, n = 2000) |&gt; dplyr::select(doc_id, product_category, text)) |&gt; dplyr::filter(product_category == &quot;Other&quot; &amp; .pred_class == &quot;Video DVD&quot;) |&gt; dplyr::inner_join( dtplyr::lazy_dt(dt) |&gt; dplyr::select(review_id, product_category) |&gt; dplyr::rename(truth_category = product_category) |&gt; dplyr::as_tibble(), by = c(&quot;doc_id&quot; = &quot;review_id&quot;) ) |&gt; dplyr::mutate(text = stringr::str_sub(text, end = 30)) |&gt; reactable::reactable(filterable = TRUE, compact = TRUE) BooksやVideoというカテゴリの商品が多いようです。 "],["session.html", "Chapter 5 Sessioninfo", " Chapter 5 Sessioninfo sessioninfo::session_info() ## ─ Session info ──────────────────────────────────────────────────────────────────────────────── ## setting value ## version R version 4.2.2 Patched (2022-11-10 r83330) ## os Ubuntu 22.04.2 LTS ## system x86_64, linux-gnu ## ui RStudio ## language (EN) ## collate ja_JP.UTF-8 ## ctype ja_JP.UTF-8 ## tz Asia/Tokyo ## date 2023-03-11 ## rstudio 2022.12.0+353 Elsbeth Geranium (server) ## pandoc 2.19.2 @ /usr/lib/rstudio-server/bin/quarto/bin/tools/ (via rmarkdown) ## ## ─ Packages ──────────────────────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## abind 1.4-5 2016-07-21 [3] CRAN (R 4.0.1) ## audubon 0.5.0 2023-02-26 [1] https://paithiov909.r-universe.dev (R 4.2.2) ## backports 1.4.1 2021-12-13 [3] RSPM (R 4.2.0) ## bit 4.0.5 2022-11-15 [3] RSPM (R 4.2.0) ## bit64 4.0.5 2020-08-30 [3] RSPM (R 4.2.0) ## bookdown 0.33 2023-03-06 [1] RSPM (R 4.2.0) ## broom * 1.0.3 2023-01-25 [3] RSPM (R 4.2.0) ## bslib 0.4.2 2022-12-16 [3] RSPM (R 4.2.0) ## cachem 1.0.7 2023-02-24 [3] RSPM (R 4.2.0) ## car 3.1-1 2022-10-19 [1] RSPM (R 4.2.0) ## carData 3.0-5 2022-01-06 [1] RSPM (R 4.2.0) ## class 7.3-21 2023-01-23 [3] RSPM (R 4.2.0) ## cli 3.6.0 2023-01-09 [3] RSPM (R 4.2.0) ## codetools 0.2-19 2023-02-01 [3] RSPM (R 4.2.0) ## colorspace 2.1-0 2023-01-23 [3] RSPM (R 4.2.0) ## conflicted 1.2.0 2023-02-01 [1] RSPM (R 4.2.0) ## crayon 1.5.2 2022-09-29 [3] RSPM (R 4.2.0) ## crosstalk 1.2.0 2021-11-04 [3] CRAN (R 4.1.2) ## curl 5.0.0 2023-01-12 [3] RSPM (R 4.2.0) ## data.table 1.14.8 2023-02-17 [3] RSPM (R 4.2.0) ## dials * 1.1.0 2022-11-04 [1] RSPM (R 4.2.0) ## DiceDesign 1.9 2021-02-13 [1] RSPM (R 4.2.0) ## digest 0.6.31 2022-12-11 [3] RSPM (R 4.2.0) ## dplyr * 1.1.0 2023-01-29 [3] RSPM (R 4.2.0) ## dtplyr 1.3.0 2023-02-24 [1] CRAN (R 4.2.2) ## ellipsis 0.3.2 2021-04-29 [3] CRAN (R 4.1.1) ## evaluate 0.20 2023-01-17 [3] RSPM (R 4.2.0) ## fansi 1.0.4 2023-01-22 [3] RSPM (R 4.2.0) ## farver 2.1.1 2022-07-06 [3] RSPM (R 4.2.0) ## fastmap 1.1.1 2023-02-24 [3] RSPM (R 4.2.0) ## fastmatch 1.1-3 2021-07-23 [3] RSPM (R 4.2.0) ## forcats 1.0.0 2023-01-29 [1] RSPM (R 4.2.0) ## foreach 1.5.2 2022-02-02 [3] RSPM (R 4.2.0) ## furrr 0.3.1 2022-08-15 [3] RSPM (R 4.2.0) ## future 1.31.0 2023-02-01 [3] RSPM (R 4.2.0) ## future.apply 1.10.0 2022-11-05 [3] RSPM (R 4.2.0) ## generics 0.1.3 2022-07-05 [3] RSPM (R 4.2.0) ## ggplot2 * 3.4.1 2023-02-10 [3] RSPM (R 4.2.0) ## ggpubr 0.6.0 2023-02-10 [1] CRAN (R 4.2.2) ## ggrepel 0.9.3 2023-02-03 [1] CRAN (R 4.2.2) ## ggsignif 0.6.4 2022-10-13 [1] RSPM (R 4.2.0) ## gibasa 0.8.0 2023-03-04 [1] https://paithiov909.r-universe.dev (R 4.2.2) ## globals 0.16.2 2022-11-21 [3] RSPM (R 4.2.0) ## glue 1.6.2 2022-02-24 [3] RSPM (R 4.2.0) ## gower 1.0.1 2022-12-22 [3] RSPM (R 4.2.0) ## GPfit 1.0-8 2019-02-08 [1] RSPM (R 4.2.0) ## gtable 0.3.1 2022-09-01 [3] RSPM (R 4.2.0) ## hardhat 1.2.0 2022-06-30 [3] RSPM (R 4.2.0) ## highr 0.10 2022-12-22 [3] RSPM (R 4.2.0) ## hms 1.1.2 2022-08-19 [3] RSPM (R 4.2.0) ## htmltools 0.5.4 2022-12-07 [3] RSPM (R 4.2.0) ## htmlwidgets 1.6.1 2023-01-07 [3] RSPM (R 4.2.0) ## httpgd 1.3.1 2023-01-30 [3] RSPM (R 4.2.0) ## infer * 1.0.4 2022-12-02 [1] RSPM (R 4.2.0) ## ipred 0.9-13 2022-06-02 [3] RSPM (R 4.2.0) ## iterators 1.0.14 2022-02-05 [3] RSPM (R 4.2.0) ## jquerylib 0.1.4 2021-04-26 [3] CRAN (R 4.1.2) ## jsonlite 1.8.4 2022-12-06 [3] RSPM (R 4.2.0) ## knitr 1.42 2023-01-25 [3] RSPM (R 4.2.0) ## labeling 0.4.2 2020-10-20 [3] RSPM (R 4.2.0) ## later 1.3.0 2021-08-18 [3] CRAN (R 4.1.1) ## lattice 0.20-45 2021-09-22 [4] CRAN (R 4.2.0) ## lava 1.7.2.1 2023-02-27 [3] RSPM (R 4.2.0) ## lhs 1.1.6 2022-12-17 [1] RSPM (R 4.2.0) ## lifecycle 1.0.3 2022-10-07 [3] RSPM (R 4.2.0) ## listenv 0.9.0 2022-12-16 [3] RSPM (R 4.2.0) ## lubridate 1.9.2 2023-02-10 [3] RSPM (R 4.2.0) ## magrittr 2.0.3 2022-03-30 [3] RSPM (R 4.2.0) ## MASS 7.3-58.2 2023-01-23 [3] RSPM (R 4.2.0) ## Matrix 1.5-3 2022-11-11 [3] RSPM (R 4.2.0) ## memoise 2.0.1 2021-11-26 [3] RSPM (R 4.2.0) ## modeldata * 1.1.0 2023-01-25 [3] RSPM (R 4.2.0) ## munsell 0.5.0 2018-06-12 [3] CRAN (R 4.0.1) ## nnet 7.3-18 2022-09-28 [3] RSPM (R 4.2.0) ## nsyllable 1.0.1 2022-02-28 [1] RSPM (R 4.2.0) ## parallelly 1.34.0 2023-01-13 [3] RSPM (R 4.2.0) ## parsnip * 1.0.4 2023-02-22 [1] CRAN (R 4.2.2) ## pillar 1.8.1 2022-08-19 [3] RSPM (R 4.2.0) ## pkgconfig 2.0.3 2019-09-22 [3] CRAN (R 4.0.1) ## prodlim 2019.11.13 2019-11-17 [3] RSPM (R 4.2.0) ## purrr * 1.0.1 2023-01-10 [3] RSPM (R 4.2.0) ## quanteda 3.2.4 2022-12-08 [1] RSPM (R 4.2.0) ## quanteda.textstats 0.96 2022-09-19 [1] RSPM (R 4.2.0) ## R.methodsS3 1.8.2 2022-06-13 [3] RSPM (R 4.2.0) ## R.oo 1.25.0 2022-06-12 [3] RSPM (R 4.2.0) ## R.utils 2.12.2 2022-11-11 [3] RSPM (R 4.2.0) ## R6 2.5.1 2021-08-19 [3] RSPM (R 4.2.0) ## ranger * 0.14.1 2022-06-18 [1] RSPM (R 4.2.0) ## Rcpp 1.0.10 2023-01-22 [3] RSPM (R 4.2.0) ## RcppParallel 5.1.7 2023-02-27 [1] CRAN (R 4.2.2) ## reactable 0.4.3 2023-01-07 [1] RSPM (R 4.2.0) ## reactR 0.4.4 2021-02-22 [1] RSPM (R 4.2.0) ## readr 2.1.4 2023-02-10 [1] CRAN (R 4.2.2) ## recipes * 1.0.5 2023-02-20 [3] RSPM (R 4.2.0) ## rlang 1.0.6 2022-09-24 [3] RSPM (R 4.2.0) ## rmarkdown 2.20 2023-01-19 [3] RSPM (R 4.2.0) ## ROSE 0.0-4 2021-06-14 [1] RSPM (R 4.2.0) ## rpart 4.1.19 2022-10-21 [3] RSPM (R 4.2.0) ## rsample * 1.1.1 2022-12-07 [3] RSPM (R 4.2.0) ## rstatix 0.7.2 2023-02-01 [1] RSPM (R 4.2.0) ## rstudioapi 0.14 2022-08-22 [3] RSPM (R 4.2.0) ## sass 0.4.5 2023-01-24 [3] RSPM (R 4.2.0) ## scales * 1.2.1 2022-08-20 [3] RSPM (R 4.2.0) ## sessioninfo 1.2.2 2021-12-06 [1] RSPM (R 4.2.0) ## stopwords 2.3 2021-10-28 [1] RSPM (R 4.2.0) ## stringi 1.7.12 2023-01-11 [3] RSPM (R 4.2.0) ## stringr 1.5.0 2022-12-02 [3] RSPM (R 4.2.0) ## survival 3.5-3 2023-02-12 [3] RSPM (R 4.2.0) ## systemfonts 1.0.4 2022-02-11 [3] RSPM (R 4.2.0) ## textrecipes * 1.0.2 2022-12-21 [1] RSPM (R 4.2.0) ## themis * 1.0.0 2022-07-02 [1] RSPM (R 4.2.0) ## tibble * 3.1.8 2022-07-22 [3] RSPM (R 4.2.0) ## tidymodels * 1.0.0 2022-07-13 [1] RSPM (R 4.2.0) ## tidyr * 1.3.0 2023-01-24 [3] RSPM (R 4.2.0) ## tidyselect 1.2.0 2022-10-10 [3] RSPM (R 4.2.0) ## timechange 0.2.0 2023-01-11 [3] RSPM (R 4.2.0) ## timeDate 4022.108 2023-01-07 [3] RSPM (R 4.2.0) ## tune * 1.0.1 2022-10-09 [1] RSPM (R 4.2.0) ## tzdb 0.3.0 2022-03-28 [3] RSPM (R 4.2.0) ## utf8 1.2.3 2023-01-31 [3] RSPM (R 4.2.0) ## V8 4.2.2 2022-11-03 [3] RSPM (R 4.2.0) ## vctrs 0.5.2 2023-01-23 [3] RSPM (R 4.2.0) ## viridisLite 0.4.1 2022-08-22 [3] RSPM (R 4.2.0) ## vroom 1.6.1 2023-01-22 [1] RSPM (R 4.2.0) ## withr 2.5.0 2022-03-03 [3] RSPM (R 4.2.0) ## workflows * 1.1.3 2023-02-22 [1] CRAN (R 4.2.2) ## workflowsets * 1.0.0 2022-07-12 [1] RSPM (R 4.2.0) ## xfun 0.37 2023-01-31 [3] RSPM (R 4.2.0) ## yaml 2.3.7 2023-01-23 [3] RSPM (R 4.2.0) ## yardstick * 1.1.0 2022-09-07 [1] RSPM (R 4.2.0) ## ## [1] /home/paithiov909/R/x86_64-pc-linux-gnu-library/4.2 ## [2] /usr/local/lib/R/site-library ## [3] /usr/lib/R/site-library ## [4] /usr/lib/R/library ## ## ─────────────────────────────────────────────────────────────────────────────────────────────── "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
