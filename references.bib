@article{10.1093/bioinformatics/bty373,
  author = {Nembrini, Stefano and König, Inke R and Wright, Marvin N},
  title = "{The revival of the Gini importance?}",
  journal = {Bioinformatics},
  volume = {34},
  number = {21},
  pages = {3711-3718},
  year = {2018},
  month = {05},
  abstract = "{Random forests are fast, flexible and represent a robust approach to analyze high dimensional data. A key advantage over alternative machine learning algorithms are variable importance measures, which can be used to identify relevant features or perform variable selection. Measures based on the impurity reduction of splits, such as the Gini importance, are popular because they are simple and fast to compute. However, they are biased in favor of variables with many possible split points and high minor allele frequency.We set up a fast approach to debias impurity-based variable importance measures for classification, regression and survival forests. We show that it creates a variable importance measure which is unbiased with regard to the number of categories and minor allele frequency and almost as fast as the standard impurity importance. As a result, it is now possible to compute reliable importance estimates without the extra computing cost of permutations. Further, we combine the importance measure with a fast testing procedure, producing p-values for variable importance with almost no computational overhead to the creation of the random forest. Applications to gene expression and genome-wide association data show that the proposed method is powerful and computationally efficient.The procedure is included in the ranger package, available at https://cran.r-project.org/package=ranger and https://github.com/imbs-hl/ranger.Supplementary data are available at Bioinformatics online.}",
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/bty373},
  url = {https://doi.org/10.1093/bioinformatics/bty373},
  eprint = {https://academic.oup.com/bioinformatics/article-pdf/34/21/3711/48920786/bioinformatics\_34\_21\_3711\_s1.pdf}
}

@article{Breiman2001,
  author={Breiman, Leo},
  title={Random Forests},
  journal={Machine Learning},
  year={2001},
  month={Oct},
  day={01},
  volume={45},
  number={1},
  pages={5-32},
  abstract={Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148--156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
  issn={1573-0565},
  doi={10.1023/A:1010933404324},
  url={https://doi.org/10.1023/A:1010933404324}
}

@article{JSSv077i01,
  title={ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R},
  volume={77},
  url={https://www.jstatsoft.org/index.php/jss/article/view/v077i01},
  doi={10.18637/jss.v077.i01},
  abstract={We introduce the C++ application and R package ranger. The software is a fast implementation of random forests for high dimensional data. Ensembles of classification, regression and survival trees are supported. We describe the implementation, provide examples, validate the package with a reference implementation, and compare runtime and memory usage with other implementations. The new software proves to scale best with the number of features, samples, trees, and features tried for splitting. Finally, we show that ranger is the fastest and most memory efficient implementation of random forests to analyze data on the scale of a genome-wide association study.},
  number={1},
  journal={Journal of Statistical Software},
  author={Wright, Marvin N. and Ziegler, Andreas},
  year={2017},
  pages={1–17}
}
